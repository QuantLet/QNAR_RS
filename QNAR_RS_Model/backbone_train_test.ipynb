{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T09:56:29.356396Z",
     "start_time": "2024-12-24T09:56:27.472941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tensor_loaded:  torch.Size([2907, 10, 1536])\n",
      "torch.Size([32, 1536]) torch.Size([32, 10, 1536]) torch.Size([2, 1626]) torch.Size([287, 1536])\n",
      "torch.Size([32, 1536]) torch.Size([32, 10, 1536]) torch.Size([2, 1626]) torch.Size([287, 1536])\n",
      "torch.Size([32, 1536]) torch.Size([32, 10, 1536]) torch.Size([2, 1626]) torch.Size([287, 1536])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 178\u001B[0m\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model, test_loader, edge_index, x, num_nodes, time_series_length, embedding_size\n\u001B[1;32m    177\u001B[0m \u001B[38;5;66;03m# 运行训练并获取返回的变量\u001B[39;00m\n\u001B[0;32m--> 178\u001B[0m model, test_loader, edge_index, x, num_nodes, time_series_length, embedding_size \u001B[38;5;241m=\u001B[39m run_with_validation_and_early_stopping()\n",
      "Cell \u001B[0;32mIn[5], line 105\u001B[0m, in \u001B[0;36mrun_with_validation_and_early_stopping\u001B[0;34m()\u001B[0m\n\u001B[1;32m    103\u001B[0m output \u001B[38;5;241m=\u001B[39m model(search_batch, time_series_batch, edge_index, x)\n\u001B[1;32m    104\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, label_batch)\n\u001B[0;32m--> 105\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m    106\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    107\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/xai/lib/python3.12/site-packages/torch/_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    524\u001B[0m     )\n\u001B[0;32m--> 525\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    526\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    527\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/xai/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m _engine_run_backward(\n\u001B[1;32m    268\u001B[0m     tensors,\n\u001B[1;32m    269\u001B[0m     grad_tensors_,\n\u001B[1;32m    270\u001B[0m     retain_graph,\n\u001B[1;32m    271\u001B[0m     create_graph,\n\u001B[1;32m    272\u001B[0m     inputs,\n\u001B[1;32m    273\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    274\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    275\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/xai/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    745\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    746\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from shared.GNNModel import GNNModel\n",
    "\n",
    "def run_with_validation_and_early_stopping():\n",
    "    # 加载数据\n",
    "    loaded_data = torch.load('training_data.pt')\n",
    "    X_tensor_loaded = loaded_data['X_tensor']  \n",
    "    search_terms_tensor_loaded = loaded_data['search_terms_tensor']\n",
    "    print(\"X_tensor_loaded: \", X_tensor_loaded.shape)\n",
    "    labels_tensor_loaded = loaded_data['labels_tensor']\n",
    "\n",
    "    max_label = labels_tensor_loaded.max().item()\n",
    "    num_nodes = max_label + 1\n",
    "    time_series_length = X_tensor_loaded.size(1)\n",
    "    embedding_size = X_tensor_loaded.size(2)\n",
    "\n",
    "    # 加载图\n",
    "    gml_file = './pmfg_graph.graphml'\n",
    "    G = nx.read_graphml(gml_file)\n",
    "    data = from_networkx(G)\n",
    "    if 'x' not in data:\n",
    "        data.x = torch.rand(G.number_of_nodes(), embedding_size)\n",
    "    edge_index = data.edge_index\n",
    "    x = data.x\n",
    "\n",
    "    # 将数据随机打乱并分为训练集和测试集 (80%训练+验证, 20%测试)\n",
    "    total_samples = X_tensor_loaded.size(0)\n",
    "    indices = torch.randperm(total_samples)\n",
    "    test_ratio = 0.2\n",
    "    test_size = int(total_samples * test_ratio)\n",
    "    trainval_size = total_samples - test_size\n",
    "\n",
    "    trainval_indices = indices[:trainval_size]\n",
    "    test_indices = indices[test_size:]\n",
    "\n",
    "    X_trainval = X_tensor_loaded[trainval_indices]\n",
    "    search_trainval = search_terms_tensor_loaded[trainval_indices]\n",
    "    y_trainval = labels_tensor_loaded[trainval_indices]\n",
    "\n",
    "    X_test = X_tensor_loaded[test_indices]\n",
    "    search_test = search_terms_tensor_loaded[test_indices]\n",
    "    y_test = labels_tensor_loaded[test_indices]\n",
    "\n",
    "    # 从训练+验证集中再分10%出来作为验证集\n",
    "    val_ratio = 0.1\n",
    "    val_size = int(trainval_size * val_ratio)\n",
    "    train_size = trainval_size - val_size\n",
    "\n",
    "    train_indices, val_indices = random_split(range(trainval_size), [train_size, val_size])\n",
    "    train_indices = torch.tensor(train_indices.indices)\n",
    "    val_indices = torch.tensor(val_indices.indices)\n",
    "\n",
    "    X_train = X_trainval[train_indices]\n",
    "    search_train = search_trainval[train_indices]\n",
    "    y_train = y_trainval[train_indices]\n",
    "\n",
    "    X_val = X_trainval[val_indices]\n",
    "    search_val = search_trainval[val_indices]\n",
    "    y_val = y_trainval[val_indices]\n",
    "\n",
    "    # 构建 DataLoader\n",
    "    train_dataset = TensorDataset(search_train, X_train, y_train)\n",
    "    val_dataset = TensorDataset(search_val, X_val, y_val)\n",
    "    test_dataset = TensorDataset(search_test, X_test, y_test)\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 定义模型、优化器、损失函数\n",
    "    model = GNNModel(num_nodes=num_nodes, embedding_size=embedding_size, dropout=0.5)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 50\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    no_improve_count = 0\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for search_batch, time_series_batch, label_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            print(search_batch.shape, time_series_batch.shape, edge_index.shape, x.shape)\n",
    "            output = model(search_batch, time_series_batch, edge_index, x)\n",
    "            loss = criterion(output, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct += (predicted == label_batch).sum().item()\n",
    "            total += label_batch.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for search_batch, time_series_batch, label_batch in val_loader:\n",
    "                output = model(search_batch, time_series_batch, edge_index, x)\n",
    "                loss = criterion(output, label_batch)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                val_correct += (predicted == label_batch).sum().item()\n",
    "                val_total += label_batch.size(0)\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Early Stopping 检查\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improve_count = 0\n",
    "            # 保存最佳模型参数\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            if no_improve_count >= patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # 绘制训练和验证的Loss与Accuracy\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(train_accuracies, label='Train Acc')\n",
    "    plt.plot(val_accuracies, label='Val Acc')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 返回必要的变量以便后续使用\n",
    "    return model, test_loader, edge_index, x, num_nodes, time_series_length, embedding_size\n",
    "\n",
    "# 运行训练并获取返回的变量\n",
    "model, test_loader, edge_index, x, num_nodes, time_series_length, embedding_size = run_with_validation_and_early_stopping()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code is for testing, with \"hit rate\", which means the top 10 out of 300+ courses recommendation contains the real visit one. And this rate based on the saved model is 86.6% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:18:53.553468Z",
     "start_time": "2024-12-23T08:18:53.389506Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 38\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHit Rate@10: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhit_rate_10\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 38\u001B[0m     run_evaluation()\n",
      "Cell \u001B[0;32mIn[6], line 29\u001B[0m, in \u001B[0;36mrun_evaluation\u001B[0;34m()\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_evaluation\u001B[39m():\n\u001B[1;32m     26\u001B[0m \n\u001B[1;32m     27\u001B[0m \n\u001B[1;32m     28\u001B[0m     \u001B[38;5;66;03m# 初始化模型并加载参数\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m     model \u001B[38;5;241m=\u001B[39m GNNModel(num_nodes\u001B[38;5;241m=\u001B[39mnum_nodes, time_series_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, embedding_size\u001B[38;5;241m=\u001B[39membedding_size)\n\u001B[1;32m     30\u001B[0m     model\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbest_model.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m, map_location\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     31\u001B[0m     model\u001B[38;5;241m.\u001B[39meval()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'num_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_hit_rate_k(model, test_loader, edge_index, x, k=10):\n",
    "    model.eval()\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for search_batch, time_series_batch, label_batch in test_loader:\n",
    "            output = model(search_batch, time_series_batch, edge_index, x)\n",
    "            _, topk_indices = torch.topk(output, k, dim=1)\n",
    "\n",
    "            for i in range(label_batch.size(0)):\n",
    "                label = label_batch[i].item()\n",
    "                recommended_list = topk_indices[i].tolist()\n",
    "                if label in recommended_list:\n",
    "                    hits += 1\n",
    "                total += 1\n",
    "\n",
    "    hit_rate = hits / total if total > 0 else 0.0\n",
    "    return hit_rate\n",
    "\n",
    "def run_evaluation():\n",
    "\n",
    "    # 初始化模型并加载参数\n",
    "    model = GNNModel(num_nodes=num_nodes, time_series_length=10, embedding_size=embedding_size)\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\", map_location='cpu'))\n",
    "    model.eval()\n",
    "\n",
    "    # 计算 Hit Rate@10\n",
    "    hit_rate_10 = evaluate_hit_rate_k(model, test_loader, edge_index, x, k=10)\n",
    "    print(f\"Hit Rate@10: {hit_rate_10:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_evaluation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
